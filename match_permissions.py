#!/usr/bin/python3

"""
This script reads app_permission_weights.json (written by parse_xml.py) to
get the names of permissions and permission_weights.json (written by tensorflow_learn.py)
to get the permission weights from a trained ML model. It then matches the permission
weights to the human-readable names for them, and prints them out, sorted by the weights.
So the first permission listed is the one most indicative of maliciousness, and the first
one in the second list is the one most indicative of benign (the lists are just mirror
images of each other).
"""

import json

def main():
    with open('app_permission_vectors.json') as vectors:
        # Dataset of permission names that were used in the model
        permission_names = json.load(vectors)['permissions']

    with open('permission_weights.json') as weights:
        # Tensorflow model calculated weights for every permission
        permission_weights = json.load(weights)

    # Separate malicous and benign weights
    malicious_weights = [weight[0] for weight in permission_weights]
    benign_weights = [weight[1] for weight in permission_weights]

    # Sort weights in descending order
    malicious_indices=sorted(range(len(malicious_weights)), key=lambda k: malicious_weights[k], reverse=True)
    benign_indices=sorted(range(len(benign_weights)), key=lambda k: benign_weights[k], reverse=True)

    # Prints the rank of each permission, its weight, and the permission name
    print('MALICIOUS PERMISSION RANKINGS:\n')
    for i,x in enumerate(malicious_indices):
        print ('{}. {} {}'.format(i, permission_names[x], malicious_weights[x]))

    print ('\n\n\n\n\nBENIGN PERMISSION RANKINGS:\n')
    for i,x in enumerate(benign_indices):
        print ('{}. {} {}'.format(i, permission_names[x], benign_weights[x]))

if __name__=='__main__':
    main()
