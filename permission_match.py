import json


with open("app_permission_vectors.json",'r') as vectors:
#Dataset of permission names that were used in the model
    permission_names = json.load(vectors)['permissions']
with open("permission_bias.json",'r') as biases:
#Tensorflow model calculated weights for every permission
    permission_biase = json.load(biases)
#Malicous and Benign weights separated
malicious_weights = [weight[0] for weight in permission_biase]
benign_weights = [weight[1] for weight in permission_biase] 
#Sorts Malicious weights in reverse order (Greatest->Least)
malicious_indices=sorted(range(len(malicious_weights)),key=lambda k: malicious_weights[k],reverse=True)
#Same as above for Benign Weights (Greatest->Least)
benign_indices=sorted(range(len(benign_weights)),key=lambda k: benign_weights[k],reverse=True)

#Prints the rank of each permission, its weight, and the permission name associated with that weight
#Shows us the "most likely" permission to the "least likely" permission for indicating if an application is malicious, according to Tensorflow model
print("NOW PRINTING MALICIOUS PERMISSION RANKINGS:\n")
for i,x in enumerate(malicious_indices):
    print ('{}. {} {}'.format(i,permission_names[x],malicious_weights[x]))
print ("\n\n\n\n\nNOW PRINTING BENIGN PERMISSION RANKINGS:\n")

for i,x in enumerate(benign_indices): 
    print ('{}. {} {}'.format(i,permission_names[x],benign_weights[x]))
