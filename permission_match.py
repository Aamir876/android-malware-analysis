#!/usr/bin/python3

"""
This script reads app_permission_weights.json (written by parse_xml.py) to
get the names of permissions and permission_bias.json (written by tensorflow_learn.py)
to get the permission weights from a trained ML model. It then matches the permission
weights to the human-readable names for them, and prints them out, sorted by the weights.
So the first permission listed is the one most indicative of maliciousness, and the first
one in the second list is the one most indicative of benign (the lists are just mirror
images of each other).
"""

import json


with open("app_permission_vectors.json",'r') as vectors:
#Dataset of permission names that were used in the model
    permission_names = json.load(vectors)['permissions']
with open("permission_bias.json",'r') as biases:
#Tensorflow model calculated weights for every permission
    permission_biase = json.load(biases)
#Malicous and Benign weights separated
malicious_weights = [weight[0] for weight in permission_biase]
benign_weights = [weight[1] for weight in permission_biase] 
#Sorts Malicious weights in reverse order (Greatest->Least)
malicious_indices=sorted(range(len(malicious_weights)),key=lambda k: malicious_weights[k],reverse=True)
#Same as above for Benign Weights (Greatest->Least)
benign_indices=sorted(range(len(benign_weights)),key=lambda k: benign_weights[k],reverse=True)

#Prints the rank of each permission, its weight, and the permission name associated with that weight
#Shows us the "most likely" permission to the "least likely" permission for indicating if an application is malicious, according to Tensorflow model
print("NOW PRINTING MALICIOUS PERMISSION RANKINGS:\n")
for i,x in enumerate(malicious_indices):
    print ('{}. {} {}'.format(i,permission_names[x],malicious_weights[x]))
print ("\n\n\n\n\nNOW PRINTING BENIGN PERMISSION RANKINGS:\n")

for i,x in enumerate(benign_indices): 
    print ('{}. {} {}'.format(i,permission_names[x],benign_weights[x]))
